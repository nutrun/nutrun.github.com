<?xml version="1.0" encoding="utf-8" ?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>nutrun</title>
  <subtitle>nutrun atom feed.</subtitle>
  <link href="http://nutrun.com/feed.atom" rel="self" />
  <link href="http://nutrun.com/" />
  <id>http://nutrun.com/</id>
  <updated>2010-11-17T00:00:00+00:00</updated>
  <author>
    <name>George Malamidis</name>
  </author>
  <entry>
    <title>  Supercharged ruby console output</title>
    <link href="http://nutrun.com/weblog/2010/11/17/supercharged-ruby-console-output.html" type="text/html" />
    <id>http://nutrun.com/weblog/2010/11/17/supercharged-ruby-console-output.html</id>
    <updated>2010-11-17T00:00:00+00:00</updated>
    <content type="xhtml">
      <div class="article">
        <div>
          <span class="date">Nov 17 2010</span>
        </div>
        <h2 class="title">Supercharged ruby console output</h2>
        <p>
          <a href="https://gist.github.com/703943">https://gist.github.com/703943</a>
        </p>
      </div>
    </content>
  </entry>
  <entry>
    <title>  Sinatra reloader</title>
    <link href="http://nutrun.com/weblog/2010/06/24/sinatra-reloader.html" type="text/html" />
    <id>http://nutrun.com/weblog/2010/06/24/sinatra-reloader.html</id>
    <updated>2010-06-24T00:00:00+00:00</updated>
    <content type="xhtml">
      <div class="article">
        <div>
          <span class="date">Jun 24 2010</span>
        </div>
        <h2 class="title">Sinatra reloader</h2>
        <p>
          When I first started using it to write web apps a couple of years ago,
          <a href="http://www.sinatrarb.com/" title="Sinatra">Sinatra</a>
          supported code reloading in development mode. That feature was dropped from the core of Sinatra at some point and we just got used to restarting the app every time we made a change whilst developing, it's not that huge an overhead, especially considering Sinatra's fast start up.
        </p>
        <p>
          I recently had to work on a Rails codebase for a while, which reminded me that code reloading without restarting in dev mode is functionality I don't mind spoiling myself with. At the time,
          <a href="http://twitter.com/abhinay" title="">Abs</a>
          pointed me to
          <a href="http://github.com/rkh/sinatra-reloader" title="rkh's sinatra-reloader at master - GitHub">sinatra-reloader</a>
          which I installed and used in a couple of apps and it works well. As I'm writing this, I'm also looking at
          <a href="http://github.com/rack/rack/blob/master/lib/rack/reloader.rb" title="lib/rack/reloader.rb at master from rack's rack - GitHub">Rack::Reloader</a>,
          which I've never used and seems somewhat different with its own set of interesting features.
          <a href="http://rtomayko.github.com/shotgun/" title="shotgun(1) - reloading rack development server">Shotgun</a>
          is out of the question for me, because it feels like manually restarting the app is faster than the time Shotgun takes to load everything per request.
        </p>
        <p>
          <a href="http://rvm.beginrescueend.com/" title="RVM: Ruby Version Manager -&#x000A;        RVM Ruby Version Manager - Documentation">RVM</a>
          has prompted me to switch between Ruby versions more often than in the past, resulting in installing gems more frequently than I used to, which in turn brings out an OCD side of me when it comes to gems that download other gems as dependencies. That's the one thing that bugs me about sinatra-reloader and since I found myself with a bit of time on my hands, I wrote my own Sinatra reloader which I've put in
          <a href="http://gist.github.com/450814" title="gist: 450814 - Code reloading for Sinatra- GitHub">this gist</a>
          in case someone else finds it useful.
        </p>
        <p>
          It works by reloading all source files and routes when it detects a change. This is less efficient than selectively reloading only code from files that have changed, although I tried it in a few of my projects without noticeable penalties. A thing to watch out for is that once a constant has been loaded, it will still be around after you delete the code that declares it. Restarting is required for such changes to take effect. I've also noticed a similar issue with classes that extend
          <code>Sequel::Model</code>
          - if I run a migration and don't restart, database field mappings don't get updated, because Sequel makes those mappings at the time
          <code>Sequel::Model</code>
          is subclassed.
        </p>
        <p>
          In summary, if you don't mind installing a bunch of gems you're likely to never use, I recommend
          <a href="http://github.com/rkh/sinatra-reloader" title="rkh's sinatra-reloader at master - GitHub">sinatra-reloader</a>.
          If you're after code reloading which you might want to customise with a couple of lines of code on the spot to suit your particular project's needs,
          <a href="http://gist.github.com/450814" title="gist: 450814 - Code reloading for Sinatra- GitHub">this</a>
          can be a starting point.
        </p>
      </div>
    </content>
  </entry>
  <entry>
    <title>  Incremental deployment</title>
    <link href="http://nutrun.com/weblog/2009/12/22/incremental-deployment.html" type="text/html" />
    <id>http://nutrun.com/weblog/2009/12/22/incremental-deployment.html</id>
    <updated>2009-12-22T00:00:00+00:00</updated>
    <content type="xhtml">
      <div class="article">
        <div>
          <span class="date">Dec 22 2009</span>
        </div>
        <h2 class="title">Incremental deployment</h2>
        <p>
          I've recently had a chance to look at a high availability system designed and built by
          <a href="http://www.forward.co.uk/" title="Forward: Connecting business with customers and people with products online">Forward</a>
          colleagues
          <a href="http://adkent.com/" title="adkent.com">Andy Kent</a>
          and
          <a href="http://oobaloo.co.uk/" title="Paul Ingles - Articles">Paul Ingles</a>.
          It is a critical web service with a very high impact of failure. Essentially, it
          <b>must</b>
          stay up at all times.
        </p>
        <p>
          The service is hosted on
          <a href="http://aws.amazon.com/ec2/" title="Amazon Elastic Compute Cloud (Amazon EC2)">Amazon EC2</a>.
          It makes use of EC2's geographically distributed regions and different availability zones within each region, fronted by
          <a href="http://aws.amazon.com/elasticloadbalancing/" title="Elastic Load Balancing">AWS Elastic Load Balancing</a>
          and additional global DNS fail over outside of EC2/AWS.
        </p>
        <p>
          <a href="http://www.flickr.com/photos/nutrun/4206247218/" title="high-availability-arch by nutrunflickr, on Flickr">
            <img alt="high-availability-arch" height="309" src="http://farm5.static.flickr.com/4008/4206247218_4b8f165e0b_o.png" width="497" />
          </a>
        </p>
        <p>A part of the project that struck me as particularly interesting is the deployment strategy Paul and Andy settled on. Regardless of how much trust we have in our builds and QA process, deployments become a whole different, much more stressful activity when critical systems like the one under discussion are involved. Andy mentioned it is important to find the balance between what to automate and bits that should require manual input.</p>
        <pre>&#x000A;# deploy.rb&#x000A;&#x000A;task :us_1b do&#x000A;  set :region, 'us-east-1'&#x000A;  set :servers, us_1b&#x000A;  # More US 1b specific setup...&#x000A;end&#x000A;&#x000A;task :eu_1a do&#x000A;  set :region, 'eu-west-1'&#x000A;  set :servers, eu_1a&#x000A;  # More EU 1a specific setup...&#x000A;end</pre>
        <p>
          This service is
          <em>incrementally deployed one availability zone at a time</em>,
          e.g.
          <code>cap us_1b deploy</code>.
          Each deployment step is manual - it requires someone to push the button. This means that if something goes wrong, only part of the system will be affected, achieving significant redundancy. If the failure was severe enough to bring the system down, only one availability zone in one region will fail and the load balancers will make sure that this failure is transparent to end users and does not overall affect the entire system.
        </p>
      </div>
    </content>
  </entry>
  <entry>
    <title>  Deployment setup automation</title>
    <link href="http://nutrun.com/weblog/2009/11/10/deployment-setup-automation.html" type="text/html" />
    <id>http://nutrun.com/weblog/2009/11/10/deployment-setup-automation.html</id>
    <updated>2009-11-10T00:00:00+00:00</updated>
    <content type="xhtml">
      <div class="article">
        <div>
          <span class="date">Nov 10 2009</span>
        </div>
        <h2 class="title">Deployment setup automation</h2>
        <p>Part of my work these days has to do with building and deploying numerous experimental applications with varying life cycles. Many of these applications get built and put on a server in less than a day only to be shut down and never looked at again a couple of days later, others get turned off and revisited after some time, while others graduate to larger, wider scope systems.</p>
        <p>This means that I get to deploy applications for the first time more frequently than usual. Also, because we deploy to virtualised infrastructures (including an internal cloud, Slicehost and Amazon EC2), slice instances (servers) tend to get rebuilt more often than they would in the absence of virtualisation. First time deployments are generally more involved than subsequent ones because there is setup up to be made and software to be installed in order for the host servers to accommodate the application.</p>
        <p>One way to treat first time deployment woes is to create and maintain images of the system in the state required to host the application. I find this to work well when dealing with moderate numbers of applications and servers, whereas creating and keeping images up to date has a tendency to become tedious and inflexible as the number of applications and images increases.</p>
        <p>
          As an alternative, we can move prerequisite system setup and installations responsibility closer to the application code, in the form of an
          <code>after</code>
          hook to the
          <code>deploy:setup task</code>
          that we call the first time we deploy an application with Capistrano. Here's some Capistrano code that performs one time setup tasks.
        </p>
        <pre>&#x000A;namespace :util do&#x000A;  task :install_libraries do&#x000A;    sudo 'apt-get install libxml2 libxml2-dev libmysqlclient15-dev -y'&#x000A;  end  &#x000A;end&#x000A;&#x000A;after 'deploy:setup', 'util:install_libraries'</pre>
        <p>With this approach, the application knows how to setup the system the way it needs it to be next time it gets deployed for the first time. As an added benefit, the Capistrano code serves as documentation for the application's system requirements.</p>
      </div>
    </content>
  </entry>
  <entry>
    <title>  VCS practices over features</title>
    <link href="http://nutrun.com/weblog/2009/08/29/vcs-practices-over-features.html" type="text/html" />
    <id>http://nutrun.com/weblog/2009/08/29/vcs-practices-over-features.html</id>
    <updated>2009-08-29T00:00:00+00:00</updated>
    <content type="xhtml">
      <div class="article">
        <div>
          <span class="date">Aug 29 2009</span>
        </div>
        <h2 class="title">VCS practices over features</h2>
        <p>
          I've often heard people I know and respect say that
          <cite>
            <a href="http://git-scm.com/" title="Git - Fast Version Control System">git</a>
            is leaps and bounds better than
            <a href="http://subversion.tigris.org/" title="subversion.tigris.org">Subversion</a>
          </cite>.
          I've been a relatively early adopter of git, it's been my VCS of choice for almost two years now. Even though I find it superior to most of the competition I struggle to justify the "leaps and bounds" claim and would rather more modestly call it "a step forward".
        </p>
        <p>This is probably due to the practices we find benefit our development process. Git puts great emphasis on branching, something we generally tend to avoid (to clarify, I'm not referring to local branching). We concentrate on feedback based on the usage of our applications. This means that we strive to commit as often as possible and, most importantly, deploy to production at a constant rate. Grossly simplified, the process is: identify a small coherent feature, build it, commit it to the master branch and deploy. No part of the codebase is owned by a subdivision of the team, everyone works on everything.</p>
        <p>
          By far the most popular git commands we issue are
          <code>git pull</code>,
          <code>git add</code>
          and
          <code>git push</code>,
          not that different to
          <code>svn update</code>
          and
          <code>svn commit</code>.
        </p>
        <p>When I first started using git I was wondering if I had developed a fear of branching because of Subversion's inefficiencies in that area. In reality, I think that an environment where every developer constantly has an up to date understanding of the codebase and especially a current grasp of the design and overall vision will always be more efficient than working remotely and having merge checkpoints, no matter how cleverly the VCS handles branching. This is why I think a faster, distributed, superior at merging VCS is not something more dramatic than a desirable step forward.</p>
      </div>
    </content>
  </entry>
  <entry>
    <title>  Hello world nginx module</title>
    <link href="http://nutrun.com/weblog/2009/08/15/hello-world-nginx-module.html" type="text/html" />
    <id>http://nutrun.com/weblog/2009/08/15/hello-world-nginx-module.html</id>
    <updated>2009-08-15T00:00:00+00:00</updated>
    <content type="xhtml">
      <div class="article">
        <div>
          <span class="date">Aug 15 2009</span>
        </div>
        <h2 class="title">Hello world nginx module</h2>
        <p>
          Several times over the past few months I made short lived attempts of delving into the mechanics of
          <a href="http://nginx.net/" title="nginx">nginx</a>
          modules. Although an invaluable resource to anyone seriously interested in the subject,
          <a href="http://www.evanmiller.org/nginx-modules-guide.html" title="Emiller's Guide to Nginx Module Development">Emiller's Guide To Nginx Module Development</a>
          doesn't at the time of this writing include a quick-start example I could hack together and see in action. Getting something to run as quickly as possible is my preferred way of starting the study of new things and every time I caught myself searching the web for a "Hello world nginx module".
        </p>
        <p>
          I will not go into any details,
          <a href="http://www.evanmiller.org/nginx-modules-guide.html" title="Emiller's Guide to Nginx Module Development">Emiller's Guide</a>
          does an excellent job at that, I'm only going to mention the steps I believe are absolutely necessary to write, compile and run an nginx handler module that responds to every request with the string "Hello world".
        </p>
        <p>
          There is a minimum of two files required for writing an nginx module, the first should be called
          <code>config</code>
          and looks something like this:
        </p>
        <pre>&#x000A;ngx_addon_name=ngx_http_hello_world_module&#x000A;HTTP_MODULES="$HTTP_MODULES ngx_http_hello_world_module"&#x000A;NGX_ADDON_SRCS="$NGX_ADDON_SRCS $ngx_addon_dir/ngx_http_hello_world_module.c"</pre>
        <p>
          The second is the module's implementation in C and nginx convention suggests a name like
          <code>ngx_http_modulename_module.c</code>,
          in this case
          <code>ngx_http_hello_world_module.c</code>.
        </p>
        <pre>&#x000A;#include &lt;ngx_config.h&gt;&#x000A;#include &lt;ngx_core.h&gt;&#x000A;#include &lt;ngx_http.h&gt;&#x000A;&#x000A;static char *ngx_http_hello_world(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);&#x000A;&#x000A;static ngx_command_t  ngx_http_hello_world_commands[] = {&#x000A;&#x000A;  { ngx_string("hello_world"),&#x000A;    NGX_HTTP_LOC_CONF|NGX_CONF_NOARGS,&#x000A;    ngx_http_hello_world,&#x000A;    0,&#x000A;    0,&#x000A;    NULL },&#x000A;&#x000A;    ngx_null_command&#x000A;};&#x000A;&#x000A;&#x000A;static u_char  ngx_hello_world[] = "hello world";&#x000A;&#x000A;static ngx_http_module_t  ngx_http_hello_world_module_ctx = {&#x000A;  NULL,                          /* preconfiguration */&#x000A;  NULL,                          /* postconfiguration */&#x000A;&#x000A;  NULL,                          /* create main configuration */&#x000A;  NULL,                          /* init main configuration */&#x000A;&#x000A;  NULL,                          /* create server configuration */&#x000A;  NULL,                          /* merge server configuration */&#x000A;&#x000A;  NULL,                          /* create location configuration */&#x000A;  NULL                           /* merge location configuration */&#x000A;};&#x000A;&#x000A;&#x000A;ngx_module_t ngx_http_hello_world_module = {&#x000A;  NGX_MODULE_V1,&#x000A;  &amp;ngx_http_hello_world_module_ctx, /* module context */&#x000A;  ngx_http_hello_world_commands,   /* module directives */&#x000A;  NGX_HTTP_MODULE,               /* module type */&#x000A;  NULL,                          /* init master */&#x000A;  NULL,                          /* init module */&#x000A;  NULL,                          /* init process */&#x000A;  NULL,                          /* init thread */&#x000A;  NULL,                          /* exit thread */&#x000A;  NULL,                          /* exit process */&#x000A;  NULL,                          /* exit master */&#x000A;  NGX_MODULE_V1_PADDING&#x000A;};&#x000A;&#x000A;&#x000A;static ngx_int_t ngx_http_hello_world_handler(ngx_http_request_t *r)&#x000A;{&#x000A;  ngx_buf_t    *b;&#x000A;  ngx_chain_t   out;&#x000A;&#x000A;  r-&gt;headers_out.content_type.len = sizeof("text/plain") - 1;&#x000A;  r-&gt;headers_out.content_type.data = (u_char *) "text/plain";&#x000A;&#x000A;  b = ngx_pcalloc(r-&gt;pool, sizeof(ngx_buf_t));&#x000A;&#x000A;  out.buf = b;&#x000A;  out.next = NULL;&#x000A;&#x000A;  b-&gt;pos = ngx_hello_world;&#x000A;  b-&gt;last = ngx_hello_world + sizeof(ngx_hello_world);&#x000A;  b-&gt;memory = 1;&#x000A;  b-&gt;last_buf = 1;&#x000A;&#x000A;  r-&gt;headers_out.status = NGX_HTTP_OK;&#x000A;  r-&gt;headers_out.content_length_n = sizeof(ngx_hello_world);&#x000A;  ngx_http_send_header(r);&#x000A;&#x000A;  return ngx_http_output_filter(r, &amp;out);&#x000A;}&#x000A;&#x000A;&#x000A;static char *ngx_http_hello_world(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)&#x000A;{&#x000A;  ngx_http_core_loc_conf_t  *clcf;&#x000A;&#x000A;  clcf = ngx_http_conf_get_module_loc_conf(cf, ngx_http_core_module);&#x000A;  clcf-&gt;handler = ngx_http_hello_world_handler;&#x000A;&#x000A;  return NGX_CONF_OK;&#x000A;}</pre>
        <p>
          Both
          <code>config</code>
          and
          <code>ngx_http_hello_world_module.c</code>
          should be placed in the same directory, let's say
          <code>/etc/ngxhelloworld</code>.
          Modules are compiled into the nginx binary. To do so,
          <a href="http://wiki.nginx.org/NginxInstall" title="NginxInstall">download the nginx source</a>,
          uncompress, and in the nginx source directory run:
        </p>
        <pre>&#x000A;./configure --add-module=/etc/ngxhelloworld&#x000A;make&#x000A;sudo make install</pre>
        <p>
          Finally, add a module directive to nginx's configuration (default is
          <code>/usr/local/nginx/conf/nginx.conf</code>)
          to enable the module for a location.
        </p>
        <pre>&#x000A;location = /hello {&#x000A;  hello_world;&#x000A;}</pre>
        <p>
          At this point, we can start nginx and navigating to
          <code>http://localhost/hello</code>
          will yield the result of all this labor.
        </p>
        <p>
          Alongside Emiller's Guide, I also found reading
          <a href="http://wiki.nginx.org/Nginx3rdPartyModules" title="Nginx3rdPartyModules">nginx third party module</a>
          code helpful.
        </p>
      </div>
    </content>
  </entry>
  <entry>
    <title>  Asynchronous session content injection</title>
    <link href="http://nutrun.com/weblog/2009/08/06/asynchronous-session-content-injection.html" type="text/html" />
    <id>http://nutrun.com/weblog/2009/08/06/asynchronous-session-content-injection.html</id>
    <updated>2009-08-06T00:00:00+00:00</updated>
    <content type="xhtml">
      <div class="article">
        <div>
          <span class="date">Aug 06 2009</span>
        </div>
        <h2 class="title">Asynchronous session content injection</h2>
        <p>
          Applying a clear distinction between stateless and stateful content when designing a web application is tricky but worth tackling early so that content not specific to user sessions can benefit from web caching. The technique we are trying out for
          <a href="http://www.scramble.com/" title="">scramble.com</a>
          reminds me of what I described in
          <a href="http://nutrun.com/weblog/state-separation/" title="nutrun  » Blog Archive   » State separation">State separation</a>
          and was introduced to me by
          <a href="http://www.neophiliac.net/" title="ne•o•phil•i•ac">Mike Jones</a>
          who was inspired by the
          <em>Dynamically Update Cached Pages</em>
          chapter in
          <a href="http://www.pragprog.com/titles/fr_arr/advanced-rails-recipes" title="The Pragmatic Bookshelf | Advanced Rails Recipes">Advanced Rails Recipes</a>.
        </p>
        <p>
          <a href="http://www.flickr.com/photos/nutrun/3794424247/" title="asynchronous-session-content-injection by nutrunflickr, on Flickr">
            <img alt="asynchronous-session-content-injection" height="242" src="http://farm3.static.flickr.com/2501/3794424247_30b0d5cc52_o.png" width="331" />
          </a>
        </p>
        <p>The idea involves serving non session specific resources independent from personalized content and use AJAX calls to inject the page with session specific content.</p>
        <pre>&#x000A;require 'rubygems'&#x000A;require 'sinatra'&#x000A;require 'json'&#x000A;&#x000A;configure do&#x000A;  enable :sessions&#x000A;end&#x000A;&#x000A;get '/' do&#x000A;  headers['Cache-Control'] = 'max-age=60, must-revalidate'&#x000A;  erb :index&#x000A;end&#x000A;&#x000A;get '/userinfo' do&#x000A;  if session[:user]&#x000A;    JSON.dump(:user =&gt; session[:user])&#x000A;  else&#x000A;    halt 401&#x000A;  end&#x000A;end&#x000A;&#x000A;get '/login' do&#x000A;  session[:user] = 'rock'&#x000A;  redirect '/'&#x000A;end&#x000A;&#x000A;get '/logout' do&#x000A;  session.clear&#x000A;  redirect '/'&#x000A;end  %p
        Notice some of the headers for
        <code>'/'</code>:</pre>
        <pre>&#x000A;$ curl -I http://localhost:4567/&#x000A;Cache-Control: max-age=60, must-revalidate&#x000A;Set-Cookie: rack.session=BAh7AA%3D%3D%0A; path=/</pre>
        <p>
          The
          <code>Cache-Control</code>
          policy instructs a web cache to keep this version of the resource for 60 seconds before requesting a fresh one.
          <code>Set-Cookie</code>
          however will usually cause a web cache to never store the response and always query its back end.
        </p>
        <p>
          The following configuration tells
          <a href="http://varnish.projects.linpro.no/" title="Varnish - Trac">Varnish</a>
          to throw away the cookie from any request/response that doesn' match one of the URLs that require authorization, thus causing it to react to response cache policies.
        </p>
        <pre>&#x000A;sub vcl_recv {&#x000A;  if (req.url !~ "^(/login|/logout|/userinfo)") {&#x000A;    unset req.http.cookie;&#x000A;  }&#x000A;}&#x000A;&#x000A;sub vcl_fetch {&#x000A;  if (req.url !~ "^(/login|/logout|/userinfo)") {&#x000A;    unset obj.http.set-cookie;&#x000A;  }&#x000A;}  %p
        A snippet from the HTML response for
        <code>'/'</code>:</pre>
        <pre>&#x000A;&lt;h1&gt;Hi&lt;/h1&gt;&#x000A;&lt;div id="nav"&gt;&#x000A;  &lt;a href="/login" class='login-control'&gt;Login&lt;/a&gt;&#x000A;&lt;/div&gt;</pre>
        <p>... and the javascript for asynchronously injecting session data to the page:</p>
        <pre>&#x000A;$(function() {&#x000A;  $.getJSON('/userinfo', function(data) {&#x000A;    $('h1').text('Hi ' + data.user);&#x000A;    $('#nav .login-control').attr('href', '/logout').html('logout');&#x000A;  })&#x000A;})</pre>
        <p>In summary, it is likely that a website will have significant amounts of content that is intended for everyone without the need for personalization. The performance of serving that content can benefit from web caching, but that becomes difficult as many websites' user experience depends on the presence of user sessions. Separating stateless from session specific content at the resource level and using a combination of HTTP and AJAX to merge the results of requests for both types of resources will make stateless content cacheable by decoupling it from the unnecessary cookie dependency.</p>
        <p>
          Runnable code example :
          <a href="http://pastie.org/573878">http://pastie.org/573878</a>
        </p>
      </div>
    </content>
  </entry>
  <entry>
    <title>  Rack::CacheHeaders code</title>
    <link href="http://nutrun.com/weblog/2009/05/18/rackcacheheaders-code.html" type="text/html" />
    <id>http://nutrun.com/weblog/2009/05/18/rackcacheheaders-code.html</id>
    <updated>2009-05-18T00:00:00+00:00</updated>
    <content type="xhtml">
      <div class="article">
        <div>
          <span class="date">May 18 2009</span>
        </div>
        <h2 class="title">Rack::CacheHeaders code</h2>
        <p>
          A few months ago I
          <a href="http://nutrun.com/weblog/rack-cache-headers/" title="nutrun  » Blog Archive   » Rack cache headers">wrote</a>
          about a possible method for centrally configuring HTTP cache headers in
          <a href="http://rack.rubyforge.org/" title="Rack: a Ruby Webserver Interface">Rack</a>
          based web applications which I called
          <code>Rack::CacheHeaders</code>.
          This is useful if your application's architecture involves tools like
          <a href="http://www.squid-cache.org/" title="squid : Optimising Web Delivery">Squid</a>
          or
          <a href="http://varnish.projects.linpro.no/" title="Varnish - Trac">Varnish</a>,
          or if you are generally interested in harvesting the numerous advantages of HTTP caching for your web application.
        </p>
        <p>
          The code has evolved a bit since and proven useful in a number of production systems. I created a
          <a href="http://gist.github.com/113441" title="gist: 113441 - GitHub">gist</a>
          of
          <code>Rack::CacheHeaders</code>
          in case someone else finds it handy. The tool is not exhaustive in terms of policies as found in the HTTP
          <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html" title="HTTP/1.1: Caching in HTTP">specs</a>,
          it's a collection of the ones we needed in the projects it's been used so far. Consider adding ones you need to the gist to make the code more complete and widely useful.
        </p>
        <p>
          <code>Rack::CacheHeaders</code>
          allows configuring HTTP cache policy response headers based on request URI patterns. For example, to set the
          <code>Cache-Control: max-age</code>
          header for a
          <code>/guitars/:id</code>
          resource to one hour:
        </p>
        <pre>&#x000A;Rack::CacheHeaders.configure do |cache|&#x000A;  cache.max_age(/^\/guitars\/d+$/, 3600)&#x000A;end</pre>
        <p>
          <a href="http://gist.github.com/113441" title="gist: 113441 - GitHub">Download/develop Rack::CacheHeaders</a>
        </p>
      </div>
    </content>
  </entry>
  <entry>
    <title>  97 Things Every Software Architect Should Know</title>
    <link href="http://nutrun.com/weblog/2009/02/28/97-things-every-software-architect-should-know.html" type="text/html" />
    <id>http://nutrun.com/weblog/2009/02/28/97-things-every-software-architect-should-know.html</id>
    <updated>2009-02-28T00:00:00+00:00</updated>
    <content type="xhtml">
      <div class="article">
        <div>
          <span class="date">Feb 28 2009</span>
        </div>
        <h2 class="title">97 Things Every Software Architect Should Know</h2>
        <p>
          A few months ago I wrote one of the axioms for a community effort called
          <a href="http://97-things.near-time.net/wiki" title="Home Page for 97 Things 		 [97 Things] : Near-Time">97 Things Every Software Architect Should Know</a>
          which was driven and edited by
          <a href="http://www.monson-haefel.com/" title="Monson-Haefel's Web Site">Richard Monson-Haefel</a>.
          This collection of principles, as contributed by an impressive range of software architects around the world, was recently released as a
          <a href="http://oreilly.com/catalog/9780596522698/index.html" title="97 Things Every Software Architect Should Know | O'Reilly Media">book</a>
          by
          <a href="http://oreilly.com/" title="O'Reilly Media - Spreading the knowledge of technology innovators">O'Reilly Media</a>
          and is well worth a look if you're interested in pragmatic advice based on how some of our colleagues approach technology projects.
        </p>
      </div>
    </content>
  </entry>
  <entry>
    <title>  Caching proxy fronted web consumer</title>
    <link href="http://nutrun.com/weblog/2009/02/14/caching-proxy-fronted-web-consumer.html" type="text/html" />
    <id>http://nutrun.com/weblog/2009/02/14/caching-proxy-fronted-web-consumer.html</id>
    <updated>2009-02-14T00:00:00+00:00</updated>
    <content type="xhtml">
      <div class="article">
        <div>
          <span class="date">Feb 14 2009</span>
        </div>
        <h2 class="title">Caching proxy fronted web consumer</h2>
        <p>Consider an application which as part of its functionality queries a product search web service.</p>
        <pre>&#x000A;WEB_SERVICE_ADDRESS = 'http://www.example.com'&#x000A;&#x000A;url = URI.parse(WEB_SERVICE_ADDRESS)&#x000A;&#x000A;Net::HTTP.start(url.host, url.port) do |http|&#x000A;  http.get('/product-search', 'q' =&gt; 'guitar')&#x000A;end</pre>
        <p>Inspecting the response headers, we notice the web service instructs consumers that the results of the query will remain the same for one hour.</p>
        <pre>curl -I "http://www.example.com/product-search?q=guitar"
        HTTP/1.1 200 OK
        Content-Type: text/html
        <strong>Cache-Control: max-age=3600, must-revalidate</strong>
        Content-Length: 32650
        Date: Sat, 14 Feb 2009 13:53:31 GMT
        Age: 0
        Connection: keep-alive</pre>
        <p>At this point we can choose to ignore the cache control header and keep on querying the service for this specific resource regardless of whether the response is going to be the same. This is suboptimal for the consumer, which will suffer unnecessary latency penalties, the service, which will have to respond to inessential requests, and the network which will be subject to unnecessary bandwidth usage. Another option involves making the web consumer aware of the service's caching policies so that it only queries for data that it doesn't have or data that's become stale. This option remedies the above problems but introduces additional complexity to the consumer.</p>
        <p>A third option involves introducing a caching proxy to the web consumer's stack responsible for mediating the service/consumer interactions solely based on the content's caching characteristics.</p>
        <p>
          <a href="http://www.flickr.com/photos/nutrun/3278914298/" title="caching-proxy-fronted-web-consumer by nutrunflickr, on Flickr">
            <img alt="caching-proxy-fronted-web-consumer" height="149" src="http://farm4.static.flickr.com/3054/3278914298_f039f380ff_o.png" width="422" />
          </a>
        </p>
        <p>Benefits of this approach include: The consumer never has to deal with any caching logic; No effort is required in re-implementing cache handling code; It is likely that the caching engine will perform better than custom caching code in the consumer because it's been built and optimized for this purpose; The caching proxy can be re-used by more than one types of consumer or more than one instances of the same consumer in the stack. As a possible side-effect, the caching proxy is an additional layer to the consumer stack and this can result in network (the consumer's LAN) latency.</p>
        <p>
          Here's the configuration needed in order to use
          <a href="http://varnish.projects.linpro.no/" title="Varnish - Trac">Varnish</a>
          as a caching web consumer proxy for the above example.
        </p>
        <pre><strong># varnish.conf</strong>
        backend default {
        .host = "www.example.com";
        .port = "http";
        }</pre>
        <p>The only thing that changes in the consumer is the address it directs its requests to.</p>
        <pre>WEB_SERVICE_ADDRESS =
        <strong>'http://service-proxy'</strong>
        url = URI.parse(WEB_SERVICE_ADDRESS)
        Net::HTTP.start(url.host, url.port) do |http|
        http.get('/product-search', 'q' =&gt; 'guitar')
        end</pre>
      </div>
    </content>
  </entry>
</feed>
